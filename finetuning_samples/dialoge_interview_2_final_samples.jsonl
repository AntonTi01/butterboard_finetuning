{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Так, да, привет ещё раз. Расскажи в целом… Ну, так, объясню, наверное, у нас сейчас будет собес. Вот мы пробежимся по темам некоторым, которые участвуют у нас в грейдах, в точке в целом. Поговорим про инфраструктуру и так далее. Вот. Расскажи в целом про команду, про проекты. Какую роль ты занимал в команде? Может, что-то интересное вспомнишь? А, ещё раз всем привет! Да, в основном у меня опыт был в интехе.\nВопрос: Три-четыре года был WebMoney опыт. Касаемо проектов, самые интересные это были C2C, то есть у нас была внутренняя валюта в рамках компании, и её нужно было переводить, там, к примеру, в доллары, в рубли, то есть некоторая биржевая, так сказать, Некоторые биржи. Вот. Этот проект у нас был на Monolith. В основном из стека у нас был ASP.NET Core. Последняя версия — это был на тот момент.NET 6-й. Потом мы его тоже переписывали уже на микросервис и переносили. Был опыт с EF-Core, с Dapper. По базам данных был Postgres, SQL-сервер, Docker, то есть все вот эти новомодные штуки. Что касается самой команды, у нас она состояла из 10 до 15 человек примерно в этом интервале. Были в основном по большей части бэкэнд-разработчики на.NET и Java. Был один QI, был архитектор и был Team Lead. Вот. Второй проект — это был СБП, то есть система быстрых платежей. Нужно было как раз, чтобы в нашей системе были переводы по системе СБП. Вот. Этот проект уже был на микросервисах, сразу написан. Поэтому тоже был опыт с монолитом и с микросервисами.\nОтвет: Вот, как ты… Да какую роль в целом в команде занимал? То есть какие-то задачи, может, сам грумил?\nВопрос: У нас обучение было, да. Сперва я пришёл вообще в компанию стажёром, вот, потом вырос до сеньора. Тоже был менторинг, там два-три человека в рамках своей команды обучал. В основном просто разработчик, но вот когда мы переписывали условно на микросервисы, У меня с ними был, так сказать, небольшой опыт, но он был. Вот, там тоже нужно было принимать некоторые решения.", "output": {"hard_skills": ["ASP.NET Core", ".NET 6", "EF Core", "Dapper", "PostgreSQL", "SQL Server", "Docker", "микросервисы", "монолит"], "soft_skills": ["менторство", "командная работа", "принятие решений", "обучение"], "recommendations": ["Углубить знания в микросервисной архитектуре, чтобы более уверенно принимать решения в рамках таких проектов.", "Продолжать развивать навыки менторинга, так как это важно для карьерного роста.", "Рассмотреть изучение новых технологий и инструментов для улучшения работы с базами данных и контейнерами."]}, "chunk_id": 0, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Хорошо. Я думаю, сразу к теме будем переходить, к первой. Давай про базы поговорим. Расскажи, с какими базами работал, опыт, кейсы, может быть.\nВопрос: Угу. В основном были базы реляционные — это SKL сервер. Потом мы делали миграцию на Postgres. Вот. По новый SKL-им базам данных у нас был Mongo, Clickhouse, если его тоже можно, по сути, назвать. Но там взаимодействия было с ними мало, в основном реляционки. Касаемо Каких кейсов? Ну, это оптимизация у меня была с индексами работа, с джойнами, хронимки переписывал на EF Core, потом с ними тоже у меня был опыт. А что ещё?\nОтвет: Ну вот, прям, полноценный базовый… Сейчас уже, вот, ты, ну, с Postgres-ом, правильно, работаешь? Да, сейчас с Postgres-ом. А ты, вот, насколько глубоко, там, копал, как он устроен, про внутрянку, там, уровни изоляции, вот это вот всё?\nВопрос: Ну, про уровни изоляции и транзакций разбирал это. Про внутрянку даже был небольшой опыт, прям, с настройкой PG-конфа, вот, но не сказать, чтобы прям как-то детально. Но внутрянки, внутренние моменты базы данных копал прям хорошо разбирался, потому что на проекте у нас был прям очень сильный SQL-разработчик и получал от него опыт. А вот в целом, вот в Postgre, какие уровни изоляции, например, есть? Самый минимальный. Так, а мне слышно, да? Да, да. Ага. А, ну, по сути, в рамках нескольких баз данных, вот SQL Server у нас четыре, а в рамках Postgres у нас их тоже четыре, но уровень read and Commit там его нет. По умолчанию у нас Read and Commit идет.", "output": {"hard_skills": ["SQL Server", "PostgreSQL", "MongoDB", "ClickHouse", "оптимизация индексов", "джойны", "Entity Framework Core", "настройка PG-конфигурации"], "soft_skills": ["умение работать в команде", "навыки получения и передачи знаний", "обучаемость", "внимание к деталям"], "recommendations": ["Углубить знания о внутреннем устройстве баз данных, особенно PostgreSQL.", "Изучить больше о различных уровнях изоляции и их влиянии на производительность.", "Продолжать развивать навыки оптимизации запросов и работы с индексацией.", "Участвовать в проектах, связанных с NoSQL базами данных для расширения опыта."]}, "chunk_id": 1, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Окей, а ты вот сам как-то пользовался?\nВопрос: Ну вот, уровнями изоляции, может, какую-то транзакционность разрулила, такую сложную, или не было кейсов? А был опыт, у нас в основном был, опять, это же финтех, очень много финансовых операций, и вот когда были какие-то сложные транзакции по переводу денежных средств, там я использовал уровень «серилайзабл», чтобы была максимальная согласованность данных. Так же было использование уровня Read Committed, ну, там Для Таски уже, честно, не вспомню, но это вроде бы связано с отчётами. Там не нужна была дикая какая-то согласованность данных, нужна была максимальная производительность. Окей.\nОтвет: А если бы индексы затронуты? То есть, ты, получается, сам проектировал таблички, да, самостоятельно? Вот расскажи, чем руководствуешься, когда размечаешь индексы?\nВопрос: А, ну, сперва как, да, сперва, понятно, нужно спросить у, в целом, команды, там, кто пользуется системой, по каким столбцам, допустим, будет очень активный поиск идти. Это, там, сам либо я как-то понимаю, либо спрашиваю, условно, вот, и поактивно, ну. По каким столбцам у нас будет идти очень активный поиск? Соответственно, самое такое первое решение, которое приходит в голову, это навесить индексы. А второе, когда уже условно таблица сформирована, Обычно приходит, условно, задачка, там, что запросы выполняются долго, надо посмотреть, вот. И ты идешь, там, смотреть либо план выполнения запросов, и параллельно раскручиваешь систему, есть ли индексы. Если есть, то почему они, условно, не выполняют свою роль, условно, по ускорению запросов? Вот, то есть это в моменте уже разбираешься.", "output": {"hard_skills": ["транзакционная обработка", "уровни изоляции", "индексация в базах данных", "оптимизация запросов", "работа с финансовыми системами"], "soft_skills": ["командная работа", "коммуникация", "аналитическое мышление", "проблемное решение"], "recommendations": ["Углубить знания в области оптимизации баз данных и индексации.", "Практиковаться в проектировании более сложных систем с учетом масштабируемости.", "Развивать навыки в анализе производительности запросов и системы в целом."]}, "chunk_id": 2, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: О, а ты тут про план запросов задел. А знаешь, чем отличается вот Explain от Explain Analyze в\nВопрос: «Explain, explain, analyze» — да, я использовал. Там вроде бы, когда мы используем «explain», мы в принципе собираем статистику, ну то есть как бы чтобы нам статистика отобразилась. А с «explain, analyze» мы вроде бы её как раз прогоняем, то есть делаем загрузку всех данных, и, соответственно, у нас как бы При первом запуске запрос выполняется дольше с explain-анализом, а второй раз уже будет быстрее, потому что вся необходимая инфа загрузилась. Ага, всё так. А вот если к индексам вернуться, получается\nОтвет: А какие вообще минусы у индексов?\nВопрос: Почему на все колонки, например, их не махнуть? Да, самая главная проблема при использовании индексов — это их размер, то есть они занимают некоторую память, вот. Если мы, в принципе, на все столбцы навешаем индексы, это может привести к тому, что у нас очень быстро разрастаться будет по памяти наша таблица. Вот. И второй Вторая проблема — это когда у нас очень часто есть запросы на insert, update, delete, то при Вот в этих операциях нам нужно, собственно, перестраивать индекс. Нужно, чтобы полностью его перестроить, и чтобы он построился на новых данных. Ну и третье, еще могу сказать, это, условно, когда у нас табличка маленькая, индексы не всегда могут вообще играть роль. Условно, у нас... База данных как бы сама понимает, когда использовать план веб… Ну, использовать индекс или нет. Если, условно, таблица маленькая, мы можем просто сиквью-сканом пробежаться по ней, и этого будет достаточно. Угу, прикольно. А давай такую задачку попробуем решить, вот, например.", "output": {"hard_skills": ["SQL", "Оптимизация запросов", "Индексация баз данных"], "soft_skills": ["Коммуникабельность", "Аналитическое мышление", "Способность к обучению"], "recommendations": ["Продолжайте углубляться в оптимизацию запросов и индексацию, это ключевые навыки для работы с базами данных.", "Попробуйте больше практиковаться в решении задач, связанных с производительностью баз данных, чтобы улучшить свои навыки.", "Обратите внимание на изучение различных подходов к работе с большими объемами данных и эффективными алгоритмами."]}, "chunk_id": 3, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: У тебя есть приложение, в которое большой трафик, много запросов летит на вставку и на чтение. Вот у тебя табличка из какой-то колонки, да, на вставку в эту колонку и на чтение этой колонки. У тебя задача, вот, поменять в этой колонке тип например там со строки на число ну допустим на или наоборот вот расскажи поэтапно как бы ты Ты это делал, чтобы, там, пользователи не пострадали, чтобы сохранить вот этот вот… все данные, которые к нам приходят, и чтобы чтение не нарушать?\nВопрос: Угу. Ну, если, условно, у нас в моменте это надо сделать, то я бы к этой таблице ничего не применял бы, никаких изменений, потому что вдруг, если что-то там, условно, ну, сбой какой-то произойдёт, то могут пострадать данные. А я бы просто создал, условно, аналог этой же таблицы. Добавил бы как раз… Заменил бы вот это поле на новый тип и параллельно, условно, какими-то партициями, пачками вносил бы новые туда изменения. А давай вот поконкретнее. Вот, например, у нас вот первый релиз. Ну, я бы по-любому начал бы создавать просто новую таблицу. И, так сказать, с новым типом. Тут, наверное, можно колонку просто создать. Ну вот, а, ну можно новую колонку, кстати, да. И пока, если, условно, такая нагрузка, именно в ту колонку добавлять новые данные. Но надо только понять, как их потом джойнить потом. Вот в этом проблема. Можно, кстати, если… Ну, по-любому, нам нужно будет как-то их там между собой связывать и понимать, какой они записи конкретно делают, добавляются. Можно было бы добавить какой-то внешний ключ. Чтоб потом с помощью join-а их получить и добавить, условно, в новую следующую таблицу, которую мы будем также создавать. Ну, просто колонки в следующий раз добавим больше новых из первой таблицы.\nОтвет: Ну то есть, получается, с чтением мы ничего, да, не делаем, получается, читаем из старой тоже.\nВопрос: В первом релизе. И старый. Ну, то есть.", "output": {"hard_skills": ["Управление базами данных", "SQL", "Моделирование данных"], "soft_skills": ["Аналитическое мышление", "Проблемное решение", "Коммуникабельность"], "recommendations": ["Углубить знания в области миграции данных и управления транзакциями.", "Изучить паттерны работы с временными таблицами и партиционированием для повышения надежности.", "Практиковаться в объяснении сложных технических концепций более простым языком для лучшего общения с коллегами."]}, "chunk_id": 4, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Блин, я бы всё-таки их перенёс бы как-то. Вот если они прям мегаогромные, ты в моменте их не можешь перенести, то есть это простое какое-то будет. То есть ты нарушишь чтение, если ты начнёшь их переносить.\nВопрос: Ну, я бы тогда добавлял бы в старую, ну, сделал бы чтение из старой таблицы, к примеру, а потом уже, когда у нас всё наладилось, мы уже могли поэтапно, ну, вот как я говорил, пачками старые данные переводить в новые, условно так. А, то есть несколько релизов понадобится. Да, да, да, ну потому что разом, да, большой скоп данных, как бы, я не видел за историей, что вот такое используется. Мы вот именно как-то делили партийцами, условно, и их так внедряли.\nОтвет: У меня, Борис, есть что докинуть?\nВопрос: Да, с JSON-ом я работал. У меня был опыт прикручивания OAuth 2 протокола в нашу систему. И там нужно было… Ну, допустим, Не знаю, «Одноклассники», да, возьмем в пример, конечно. Нужно было, условно, сделать авторизацию с помощью «Одноклассников», и нужно было у конкретного пользователя, кто делает через этот сервис авторизацию, подтянуть его друзей. Собственно, эта опишка возвращала некоторый JSON-формат. И вот эти настройки нужно было как раз у нас хранить именно в JSON. вот в виде строки Это нужно было Ну, хранить их потом при получении, условно, происходит там диссерилизация, всё очень быстро маппиться к нужным свойствам и, собственно, могли дальше как-то эти данные обрабатывать. Вот. А когда нужно использовать таблички, Пример. За место Джейсона, да, именно, в столбца. Тут, наверное, вопрос, вот почему-то больше меня склоняет именно к нормализации и денормализации. А вот, к примеру, если используем термин «денормализация», иногда может быть такая ситуация, что нам скоупом, вот именно в рамках одного запроса, нужно получить опцию. в рамках одного запроса именно JSON-ом. Мы его получаем, и его можем на практике как-то использовать. Если мы говорим про обычную таблицу, то это уже нормализация как бы идет, А одним скопом запроса мы как бы не можем подтянуть данные. Там, по-любому, у нас будут джойны идти. Скорее всего, речь про это, я так предполагаю. С какими локами? Вот что-то из головы прям вылетело. Ну, я слышал про хинты на практике использовал, там, with no lock. А, скорее всего, локи про прям лок на таблицу и лок конкретно на...", "output": {"hard_skills": ["OAuth 2", "JSON", "нормализация и денормализация баз данных", "работа с API", "десериализация"], "soft_skills": ["коммуникация", "анализ", "проблемное мышление", "гибкость"], "recommendations": ["Убедитесь, что в ваших ответах вы четко формулируете мысли, чтобы избежать непонимания.", "Развивайте навыки презентации своих идей, чтобы более уверенно делиться опытом.", "Работайте над структурированием ответов, чтобы они были более последовательными и логичными.", "Углубите свои знания о базах данных, особенно в контексте оптимизации запросов и использования индексов."]}, "chunk_id": 5, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: А строки приходилось лачить?\nВопрос: Вроде бы за практику было, я вот такое вспоминаю. Селект фор апдейт. Если это речь про это, это же, по сути, тоже… Селект фор апдейт, когда мы выполняем, это вроде бы лог на конкретную строку. То есть в рамках отдельного, допустим… Потока мы можем… Ну, вот это тоже с брокерами в сообщении встречается. Как раз я про outbox-паттерн его использовал. Когда select for update дело для записи, мы в рамках как бы одного потока лодчим, вторая, собственно, ничего сделать не может, пока мы не выполним операцию в первой, ну, транзакции, так назовем.\nОтвет: Спасибо. Ладно, давайте погоним дальше, как раз к вот КРМ перейдём.\nВопрос: Ты тоже расскажи про УРМ, там, с какими работал, какие нравятся, может, какие-то интересные истории. В основном был опыт с эвкором. По большей части где-то два с половиной года только на нём работал. Что касаемо интересных практик, ну, использовал. За загрузки данных, не знаю, можно ли сказать, что это интересно было. Я, так сказать, разбирался с лишними инклюдами, которые были. Был опыт написания inner join-а, вот тоже я помню task-у, потому что include — это обычно left join. Потом… А, конфигурационные файлы. У нас всё было в рамках метода onModelCreating. Я вносил практику Так сказать, распределение по конфигурационным файлам, чтобы всё было очень удобно. Вот, что ещё? Про чиндж-трекер, ну, тут не скажу, что сильно сталкивался, просто про него слышал, там, S-Mode трекинг по мере необходимости использовал. Даппер был, даппер, вот, но с даппером, честно, ну, больше нравится F-Core, не знаю, как будто больше нравится именно с ним работать, копать, как он под капотом устроен, вот, но с даппером тоже был опыт. Небольшой, но был. А вот ты же ты говоришь, «Include», говоришь, он «inner join». А вот он всегда «inner join»? Не-не-не, я «I», я сказал. Нет, «include» — он «left join». Когда нам нужно сделать «inner join»? Вот, кстати, если... Ну, мы можем сами написать, к примеру, select main и group by, вроде бы комбинация, и тогда у нас получится inner join. Либо использовать методы операторов, конкретно этот, SQL-запрос, там, throw, inner написать, если я не ошибаюсь. Надо почитать. Я просто слышал, что он только left-joined всегда, и поэтому мы select many пишем. Вот, ну, почитаю про это. Можешь рассказать поподробнее, что за загрузка дана? Да, у нас в рамках Эвкора, чтобы получить, условно, навигационные свойства, есть три подхода. Это ленивая загрузка, когда мы просто пишем этот include, и он прямо в рамках одного запроса подгружает зависимые данные. Бывает полезно, когда нам сразу нужны данные, но когда мы их не используем, навигационные, это может только нам ухудшить по производительности, потому что время тратится. На join. Вот. Это ленивое. Явное — с помощью обращения к контексту и вызова метод entry. Ну, вызываем метод «Entry», прокидываем сущность и в зависимости от дальшей цепочки методов подгружаем либо один объект, либо коллекцию объектов. Вот. Что у нас? «Ленивая»? «Ленивая» вроде бы с помощью прокси. Там библиотека отдельно ставится, как я помню. Прокси, как там, «Entity Framework Core», и там она построена на виртуальных свойств. Вся Роль в том, что мы, к примеру, когда подгружаем основную сущность, и потом обращаемся к зависимой, она у нас только при обращении подгружается.", "output": {"hard_skills": ["SQL", "Entity Framework Core", "Dapper", "Работа с навигационными свойствами", "Оптимизация запросов"], "soft_skills": ["Коммуникация", "Аналитическое мышление", "Способность к обучению", "Гибкость"], "recommendations": ["Углубите знания в области SQL и оптимизации запросов для повышения эффективности работы с базами данных.", "Работайте над улучшением навыков общения, чтобы более четко и понятно излагать свои мысли и идеи.", "Изучите более подробно различные подходы к загрузке данных в Entity Framework Core, чтобы расширить свои знания и возможности.", "Практикуйтесь в написании сложных SQL-запросов, включая различные типы соединений, для повышения уверенности в работе с базами данных."]}, "chunk_id": 6, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: А, ну я в целом хотел про Change Tracker узнать. Так, сколько? А ты в целом, вот, ну, понимаешь примерно, что он там делает под капотом? На что он вообще повли… влиять может?\nВопрос: Да, я прям в рамках компании делал, ну, курс по EF Core и разбирал эту тему. Там прикол в том, что когда мы, допустим, получаем данные с бдшки, вот с помощью EF Core, у нас как бы под капотом создается слепок изменений. И если мы в моменте что-то редактируем и вызываем этот self-change, у нас проверяются изменения, А вот конкретно какая запись изменилась, она Выставляется ей определенный статус, там, «Modified», и она будет изменяться. Если вообще никаких изменений не было, то у нас вроде бы статус выставляется «Unchanged», то есть никак не изменено, и… Соответственно, сохранений никаких не будет происходить. Статусов может быть несколько — «Modified», «Edit», «Deleted», вроде бы, или «Remove» называется. Вот. А этот Change Tracker, он не всегда бывает, так сказать, нужен при, допустим, Get-операциях, когда нам ничего не надо изменять. Мы можем его отключить, вызвать метод «As Now Tracking», и Change Tracker будет у нас, ну, disabled, условно, выключен. Как-то так.\nОтвет: но в объекте, как вы настраивали. А может, диагонально его настраивали, вот, относительно запроса?\nВопрос: Нет, у нас он просто был по мере необходимости запросов. Вот, то есть, в моменте я что-то пишу там, и вот вызывал S-Node Tracking. Да, понятно, что, ну, это, наверное, нехорошая практика. Скорее всего, проще написать какую-то кастомную для Get-операций, которой не надо ничего менять, и вызывать его. Но вот у нас в моменте запроса выписали его, вызывали.", "output": {"hard_skills": ["EF Core", "Change Tracker", "Database Operations"], "soft_skills": ["Коммуникабельность", "Способность к обучению", "Аналитическое мышление"], "recommendations": ["Углубить знания о паттернах проектирования и хороших практиках работы с Entity Framework.", "Разработать собственные методы для оптимизации Get-операций.", "Работать над улучшением навыков формулировки и структурирования мыслей для более четкого изложения информации."]}, "chunk_id": 7, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: А там вот глобальные у него настройки есть, и там вот есть «No tracking with identity resolution». Вот туда не копал, не смотрел, что это такое. Вот, кстати, разбирал, да. Там два метода у нас есть, но разницу я уже сейчас не назову, потому что когда я разбирался, у меня голова кипела, сейчас точно не вспомню. ну там он в общем трекает только одесшники сущности чтобы не было дублей там при дикартова перемножение вот это вот все такая настройка баланс а в целом а спид куэри вот такие штуки юзал приходилось\nВопрос: А сплитквери — это вроде бы разбиение… Или нет, сплит-квери, сейчас я вспомню. У меня было на практике, когда нужно было получить, допустим, N записей из первой таблицы, поставить между ними тире и подгрузить данные из второй таблицы. Вот это, наверное, про сплит-квери. Что-то такое вспоминаю.\nОтвет: Ну да, он там все джойны выворачивает в отдельные селекты, то есть Это полезно, когда у тебя Декартова перемножение Из-за джойнов происходит, вот, взрыв данных. Распухает вот это решение, как вариант. Через отдельные. То есть он три запроса просто делает. Ну, примерно, да. А миграции как у вас?\nВопрос: Ты пользовались EF Core, а миграции как были устроены? Тоже через EF? Да, миграции были. Ну, у нас от проекта к проекту были свои приколы, а на проекте, которым я работал, то есть, у нас было всё через миграции. Там, апдейт базы, миграция, удаление, там, таблицы какой-то или колонки — тоже была миграция, собственно. А, ну, ещё у нас был прикол через отдельные скейл-файлы. То есть, у нас и была папочка «Migrations», там", "output": {"hard_skills": ["Entity Framework Core", "SQL", "Миграции баз данных", "Оптимизация запросов", "Декартово произведение"], "soft_skills": ["Аналитическое мышление", "Способность к обучению", "Коммуникабельность", "Гибкость", "Работа в команде"], "recommendations": ["Углубить знания по сплит-запросам и их применению", "Работать над структурированием своих мыслей для более четкой передачи информации", "Подготовиться к вопросам по проектам, чтобы быть более уверенным в ответах", "Изучить подробнее настройки, связанные с идентификацией и трекингом для более глубокого понимания"]}, "chunk_id": 8, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: А вот как вы их менеджили? То есть, как деплоили, например, приложение?\nВопрос: Вот этот флоу был как устроен? Преинграцию, вы хотите? Да, честно, я прям глубоко не вкопал в них, но видел, что у нас были несколько схем базовых данных, и в зависимости от той схемы, которую мы используем, там, допустим, у нас была паблик, условно, базовая, и какая-то для тестов своя, с определёнными колонками. Ну, накатывали, условно указывали схему, и к этой схеме БДшки делали просто... Релиз. Вот, как конкретно внутренне сильно не копал. Мне просто последний опыт с миграциями был небольшой, поэтому вот что успел посмотреть, то посмотрел. Ага, то есть мне вот просто понять, вот при релизе именно вот миграция в какой момент накатывалась у вас? То есть, ну, пайплайны — у нас такого не было, это как отдельно для миграций. По сути, был просто CICD, ну, там опыта с базами не было вообще никакого, чисто CICD TeamCity-ов. Угу, то есть, миграция обратно совместимая, да, её можно заранее, там, выкатить и потом катить приложение, условно, вот, плюс-минус, так, да? Да, но я не знаю, какие могут быть в этом проблемы, потому что, опять, использовал, ну, небольшой опыт с ними был, вот, и вот чисто вот такая практика была.\nОтвет: А ещё такой вопрос про внутренний пул подключений к базе. Вот, у РЭМ, например, RedBug SQL представляет свой внутренний пул, и вот Как он у вас был настроен на проекте? Знаешь ли ты, как его, там, поднастроить можно? Сталкивались, может, с проблемой выжирания коннектов к базе, например, под большой нагрузкой, или что-то в такие моменты?\nВопрос: Я видел, что у нас вперва использовался на проекте просто AddDbContext, а потом AddDbContectionPool, то есть, да, пул контекстов. С саму настройку я прямо в рамках работы не сталкивался, то есть у меня не было таких задач, но, как я помню, там были свойства Max Size Pool, вроде бы максимальное количество полов одновременных на коннекшены, и сам я с ним игрался чисто вот на практике, ну, в своём подпроекте смотрел работу внутреннюю. За какие-то более внутренние тонкости Блин, ну, честно, вот я помню, Max Size Pool был свойством, максимальное количество подключений.", "output": {"hard_skills": ["CICD", "AddDbContext", "AddDbConnectionPool", "миграции баз данных"], "soft_skills": ["честность", "открытость к обучению", "самоанализ"], "recommendations": ["Углубить знания в области миграций баз данных и их интеграции в процесс разработки.", "Изучить различные инструменты и подходы для управления подключениями к базе данных, включая настройку пулов соединений.", "Попрактиковаться в создании и управлении пайплайнами CI/CD для более глубокого понимания процессов развертывания."]}, "chunk_id": 9, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Тот в connection строке, да, ты имеешь в виду? Просто db.context.pool же ещё у EF-а есть просто сущности, и db.context.pool их пулит, чтобы не генерить много. Ну да, я, скорее всего, про… Ну вот, когда мы подключаем adb.context, у нас там использовался метод adb.context.pool.\nВопрос: Ну, по сути, просто вытаскивание её из Upsetting.json-а и прокидывание в метод, там, usePG… useNPGSQL connection, там, вроде бы так назывался.\nОтвет: И вот в этой строке настраивается ещё внутренний пул подключения самих. Ты вот… Вы его там не конфигурили, да? То есть он у вас включен, выключен был. Честно, не скажу. Не помню этого. Ну окей. А в целом сталкивался, например, с ПГ-баунсером, с балансировщиками, подключением их к базе, вот каких-то аспектов работы с ними?\nВопрос: А когда, условно, только был джуном? То такие задачи у нас были очень часто из-за нагрузки. Но опять, там у нас решали их задачи уже сеньоры. До меня прям как-то балансировщик не доходил. Я в курсе, что с помощью него можно распределять нагрузку, междуусловно. Серверами, и понимать, что в какой момент там, условно, отвалилось. Но на практике взаимодействия такого не было. Окей, у меня вроде всё, Борис, есть что добавить у тебя? А конкретно рассказать прям, что из себя представляет, или как? Ну, если хочешь, можно так, поверхностно. Да, ну, по сути, был опыт с Revit-ом, и задача у меня была, я помню точно, настройка эксченджев, прикручивания к очередям. Это когда только я вникал в Revit. Вот, был немножко… Смотрел на практике, как разворачивается аутбокс-паттерн. Это прямо в продакшене у нас было. Пробовал свои примеры посмотреть, тоже, как он реализовывается на своей практике. Что, по сути, в рамках Рэббита у нас есть экчейндж, есть очередь. Exchange связывается с очередью по routing.k. Если рассматривать, допустим, Kafka, то там схема работы немножко другая. Есть продюсер, есть, по сути, сама очередь. В рамках очереди есть топики, в рамках топиков могут быть партишены. И, по сути, из очереди сразу сообщение доставляется в продюсер. Вот. Как-то так, по сути. Про Outbox транзакшн тоже слышал, что он очень часто встречается для гарантии доставки сообщений. Потом, про гарантию доставки сообщений — это «at most once», то есть хотя бы один раз, как максимум, как минимум один раз,. At least once. И ещё какой там? Точно один раз. Вот я помню, что он очень такой… Его сложно реализовать на практике. Exactly once, да-да-да. Вот, что его на практике, ну, очень прям сложно реализовать, и практически невозможно. Ну, вот такие темы слышал про них. А у вас, ну, то есть…", "output": {"hard_skills": ["Entity Framework", "PostgreSQL", "RabbitMQ", "Kafka", "Outbox pattern", "Load balancing"], "soft_skills": ["Командная работа", "Навыки общения", "Способность к обучению", "Аналитическое мышление"], "recommendations": ["Углубить знания в настройке и конфигурации PostgreSQL и его пулов соединений.", "Получить практический опыт работы с балансировщиками нагрузки.", "Продолжать изучение паттернов работы с очередями, таких как Outbox и Exactly Once.", "Развивать навыки работы в команде и общения, чтобы более эффективно взаимодействовать с более опытными коллегами."]}, "chunk_id": 10, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Как настроена, какая гарантия была поддержана брокером вашим?\nВопрос: А тут, в зависимости от использования, допустим, у нас очень… Ну, у нас была своя система логов, то есть, вообще, самописный фреймворк. Нужно было собирать аналитику по всяким ивентам, по всяким подключенным сессиям. Здесь, когда у нас использовались логи, то при… Этой гарантии, ну, при этом функционале у нас была гарантия как максимум один раз. Во, то есть, ну, нам неважно было, потеряется сообщение в моменте или нет. Когда это уже были какие-то сложные, допустим, ну, в рамках микросервисов операции, то там уже использовался подход как минимум один раз, потому что потерять какое-то сообщение было очень, ну, так сказать, трудно. Плохо, вот, как-то так.\nОтвет: Окей, а вот если как минимум один раз гарантия доставки, вот как защититься от дублей сообщений на принимающей стороне? Вот если у тебя есть какой-то хендлер, вот как бы ты защищался? От дублей.\nВопрос: Да, в этой как раз проблеме как минимум один раз у нас может быть дубли. Там вообще, я смотрел, четыре ситуации могут быть. Ну вот, одна из них — это дубли. Допустим... Ну самый такой банальный механизм — это по какому-нибудь айдишнику в сообщении его прокидывать, и чтобы была Между ними разница. Там сообщение и конкретно идишник, допустим, пользователя уникальный. Вот. Либо если у нас event-сорсинг-архитектура по, допустим, ивенту. То есть, по ивенту уникальному мы могли в сообщение его прокидывать и его так идентифицировать, по сути, наше сообщение. Я бы…", "output": {"hard_skills": ["опыт работы с микросервисами", "знание систем логирования", "понимание гарантий доставки сообщений", "опыт работы с event-sourcing архитектурой"], "soft_skills": ["аналитическое мышление", "умение объяснять сложные концепции", "внимание к деталям"], "recommendations": ["Углубить знания в области обработки дубликатов сообщений, исследуя различные паттерны и подходы.", "Практиковать объяснение технических аспектов на более простом уровне для повышения понятности.", "Развивать навыки работы в команде, чтобы лучше взаимодействовать с коллегами при решении сложных задач."]}, "chunk_id": 11, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: В Хендлере что происходит? То есть приходит сообщение, и дальше там мы берём айдишникова?\nВопрос: Да, ну, допустим, мы берём айдишник и, условно, его вместе с общением прокидываем. Там, допустим, структура была бы у нас какая-то. Вот. Ну, и по вот этому айдишнику мы бы различали запись. А есть ли уже такая? То есть, была бы уже она обработана или нет? Если нет, то мы её оттолкаем дальше. Если да, то в целом ничего с ней не делаем. Допустим, да, если используя, ну, если в рамках аутбокса, допустим, могу сказать, если мы вот его применяем, там для столбца можем навесить статус, либо in processing, допустим, done, либо там cancelled. Если done, то, по сути, это сообщение с этим id-шником, оно уже было обработано.\nОтвет: Вот. Ну то есть, словно исключаем Outbox, просто вот делаем такую табличку и храним там айдишники. Вот так, имя ж, веду.\nВопрос: Ну если исключаем Outbox, то в какой-нибудь табличке, да, но тут тоже должна быть гарантия, что в процессе при записи в таблицу у нас не крашнется там сервер. Ну в рамках транзакции, условно, если это делать, то я думаю проблем сильных не должно быть.", "output": {"hard_skills": ["обработка сообщений", "работа с базами данных", "управление транзакциями"], "soft_skills": ["умение объяснять", "аналитическое мышление", "командная работа"], "recommendations": ["Углубить знания в области управления транзакциями для повышения надежности системы.", "Практиковать более четкое структурирование ответов для улучшения коммуникации.", "Развивать навыки работы с различными архитектурными подходами, такими как Outbox, для расширения профессионального кругозора."]}, "chunk_id": 12, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Окей, да, похоже на правду. А вот если чуть усложнить сценарий, например, у тебя какой-то хендлер принимает Сообщение с обновлением, да, апдейтом каким-то. И вот тебе прилетело два разных сообщения с двумя разными апдейтами, там, одного и того же поля, например. Но они по пути в брокере, там, перепутались. И тебе первым пришло Новое, а потом пришло устаревшее, и как бы оно перетрёт актуальное значение, то есть, данных. То есть, а стейт нарушится. Вот. Как от этого можно защититься? Так, структура. То есть, у нас два сообщения, и последнее перезатирает первое.\nВопрос: Сейчас надо подумать, как можно. Ну, мне почему-то на голову приходит, допустим, добавить какое-то свойство по времени, по дате создания, к примеру. Либо по дате обновления. Нет, по дате создания или обновления приходит в голову. Только надо подумать, как их проверять. Ну, скорее всего, по времени. То есть, если у нас последнее обновление было, допустим, Блин, вопрос. Ещё раз, можно вопрос? Я вот… Есть два сообщения. Они, по сути, первая обновляет, и вторая перезатирает значение. А у нас вообще такая струк… Ну, должна быть такая логика, что вот перезатирать? Ну, допустим, вот у нас есть такая логика. Например, у нас там… Ты пришёл на работу, у тебя там\nОтвет: миллион обработчиков, миллион всяких сообщений, и вот есть проблема, что сообщения могут перепутаться по пути к тебе, и они могут что-то заэффектить этим. То есть, типа, устаревшее сообщение в конце, оно может как-то, там, нарушить стейт. И вот надо эту проблему решить.\nВопрос: Ну если оно устаревшее, то по дате создания условно как-то можно. Сперва мы берём самые первые, которые шли, обрабатываем их как-то... Ну, можно навесить какой-нибудь таймер, допустим, через каждые 30 минут мы делаем обновление нашей записи. Не знаю, ну какое-то решение. Ну вот по дате.", "output": {"hard_skills": ["обработка сообщений", "работа с брокерами", "управление состоянием", "логика времени обновления"], "soft_skills": ["анализ", "креативное мышление", "коммуникация", "способность к решению проблем"], "recommendations": ["Углубить знания в области управления состоянием и обработки сообщений.", "Изучить паттерны проектирования для работы с асинхронными системами.", "Развивать навыки структурирования и формулирования мыслей для более четкого изложения идей.", "Практиковать формулировку более конкретных решений и подходов в ответах на технические вопросы."]}, "chunk_id": 13, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: сейчас я хочу всех сообщение есть там какой-то свой там timestamp да когда они были созданы\nВопрос: Мы айдишники уже проверяем. А, ну, так, ну, можно как? Можно применить здесь реплицирование, допустим, новые записи мы их обрабатываем, а старые мы их, допустим, просто кладём в табличку, что они, условно, были на обновлении, и никак их не трогаем, если они никак не нужны нам. Ну, помечаем, условно, статус можно для них добавить, да? Как мы помним, что они старые? А, ну, вот в голову сейчас пришло. Допустим, у вас даты есть и статус. Статус сообщения. По статусу мы, к примеру, можем для сообщения, которое вот сейчас в моменте выполняется, повесить статус «In Processing». А когда оно выполнится, мы, допустим, этот статус выдвинем в дан. И если в дан у нас успешное выполнение, то старые сообщения мы как бы, ну, не трогаем. Зачем, если у нас уже произошла запись, апдейт? Ну да, то есть мы просто их отбрасываем, они не нужны, потому что у нас более актуальный апдейт уже применен. Ну да, я, кстати, вот читал на Хабре, допустим, старые сообщения, которые уже даже не нужны, их не удаляют, а вроде бы делают репликацию и помещают, условно, в табличку, где хранятся вот… Неактуальное сообщение. Ну чтобы вот поддерживать информацию, структуру.\nОтвет: Ну это уже, да, это уже детальки.\nВопрос: Ну если… Нет, это не всегда, наверное. Если у нас есть какая-то зависимость конкретная, то, допустим, между микроси… Ну нет, здесь не всегда. Здесь, скорее всего, должна быть гарантия согласованности данных, один из принципов ASID. Вот. И такая структура, ну, не всегда пройдет. Тут, скорее всего, именно очередь, важна очередь сообщений, в каком порядке они. Угу. Ну это да, это уже в процессе обдумываешь. Ну, у нас транзакции в основном были. То есть, в рамках транзакций. И понятно, что", "output": {"hard_skills": ["репликация данных", "обработка сообщений", "принципы ACID", "структура данных", "управление транзакциями"], "soft_skills": ["аналитическое мышление", "умение работать в команде", "коммуникационные навыки", "способность к решению проблем", "критическое мышление"], "recommendations": ["Углубитесь в изучение принципов ACID и их применения в реальных проектах.", "Развивайте навыки работы с очередями сообщений и репликацией данных.", "Работайте над улучшением коммуникационных навыков, чтобы более четко доносить свои идеи.", "Регулярно практикуйтесь в решении сложных задач для развития критического мышления.", "Изучите современные подходы к управлению транзакциями и их реализации в микросервисах."]}, "chunk_id": 14, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Погнали, давай про C-sharp в целом, про.NET поговорим. Вот расскажи. С какими версиями работал.NET-а? Следишь ли за обновлениями? Может, какие-то блоги читаешь, подкасты, чатики профессиональные?\nВопрос: Да, у меня опыт был с.NET Framework 4.8. Честно, не понравилось. Вот, там было прям сложно. А потом был опыт с.NET 5 и по.NET 9. По сути, все новомодные фичи, которые выходят Ну, понятно, что они не все используются, но про них стараюсь читать, как только происходит, там, апдейт в сентябре, в ноябре. Вот, стараюсь читать. К примеру, классные штуки, которые у нас очень зашли, это рекорды в.NET 5-ом появились. Потом я слышал, прикольная штука — дом, ну, дерево выражений появилось у нас в.NET-е. Frozen Dictionary, я помню, у нас архитектор про это рассказывал. Как под капотом, честно, ну, не расскажу прям детально, но смотрел. Что ещё прикольного? Ну, там, сериализация, то есть, вот, System Tech JSON, сериализация, децерилизация улучшалась по времени. А вот, кого смотрю прям тоже, ну, Анг… Джаванович, смотрю его, у него очень классный, вроде так правильно произв… его имя, классный Классный контент из русскоязычных Ну, «Программысли» бывает тоже, чекаю. Ну, у него в последнее время такие видосы. Потом «Экскалип» смотрю, там. Его собеседования какие-то тоже прикольные. Вот. Ну, и сам, плюс, в рамках компании тоже старался делать обучающий контент.\nОтвет: А ты вот сказал, тут Net9, он ещё, получается, не вышел. Ты вот превьюшку какую-то использовал? Или ты имел в виду тут Net8?\nВопрос: По.NET 9 я посмотрел, там приколы вышли с джейсонами, какие-то отступы появились, которые в работе могут пригодиться. Я просто посмотрел там.NET.NEXT.RU, что ли, вроде бы, что-то, подкасты. Вот посмотрел, послушал их. Я думал, вы уже использовали, там, тут на 9. Не-не, ну то есть у нас как бы… А когда апдейт случается, мы не сразу на него переходим, потому что могут быть разные последствия. Через год, условно, или полгода, там, когда стабильная выйдет версия. А вы на LTS-версиях сидите, или, там, 7-й, 9-й, может? Ну, у нас, к примеру, проекты были даже на.NET 6-ом, то есть мы как бы… Ну, 6-ой LTS всё-таки. Да-да-да, мы как бы не сразу делали апдейты, потому что, ну, не всегда это может сыграть роль. Вот я помню, не знаю, честно, за Дотнет 6-й вроде бы, но... Не все проекты мы на него переводили. Могу точно… Ну, могу спутать версию, «Дотент 5-й» или «Дотент 6-й», но какая-то версия была Бак, ну, проблемный, и мы не все проекты переводили сразу.", "output": {"hard_skills": [".NET Framework 4.8", ".NET 5", ".NET 6", "System.Text.Json", "сериализация", "дерево выражений", "Frozen Dictionary"], "soft_skills": ["самообучение", "слежение за новыми трендами", "командная работа", "создание обучающего контента"], "recommendations": ["Уточнить версии .NET, с которыми работал, чтобы избежать путаницы на собеседованиях.", "Углубить знания по новым возможностям .NET 8 и 9, чтобы быть в курсе последних изменений.", "Продолжать следить за обновлениями и расширять кругозор, читая больше профессиональной литературы и слушая подкасты.", "Развивать навыки объяснения сложных концепций, чтобы более доступно делиться своими знаниями с коллегами."]}, "chunk_id": 15, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Батчами обновление, батчами удаление. Что давно просили?\nВопрос: Ага, оно… Вот execute, delete — вот это вот. Да, у нас бачи… У нас была вроде бы самописная даже технология. Да, вроде даже самописная. Мы выполняли, если большой скоуп обновлений, у нас использовался bulk update метод, вот. Под капотом, честно, не могу сказать, как он там работал, не особо вдавался. За AFCore смотрел, там прикольный агрегейт, что-то по агрегации методы ускорились, добавились даже какие-то в новой версии. Вот. А у вас самописный был bulk update или от EF Extensions, который… классная шучечка. Вот именно что он был самописным, как я вспоминаю. Там прям был самописный отдельно либо побольше. У нас очень много было самописного по NFT Framework Core. Там даже были Expression 3. На практике я посмотрел, то есть, поковырялся немного, понял, что, ну, это довольно непростая тема на самом деле, вот. Просто пару примеров с метанита посмотрел, а в работе, так сказать, мы их не часто прям писали. Они были, но не прям must-have-практика была у нас. Довольно-таки хитрая штука. Согласен. Да, ну она… По оптимизации, можно, наверное, выиграть. Я не спорю, если её добавили. Но она очень, там… Бывали такие методы, что просто посмотришь и застрелишься, условно.\nОтвет: Слушай, вот ты наверняка, там, на SpendCore писал часто какие-то интеграции, больше ничего не делал. Вот, там, в SpendCore есть такая школа, как Http Client Factory. Вот, может, знаешь, зачем её добавили, какие она проблемы решает?\nВопрос: Пользуйтесь, если вы вообще… Да, знаю несколько проблем. Одна из них — это, ну, тоже критичная. Допустим, когда мы создаём новый HTTP-клайент, у нас может быть закончится свободный пул подключений. При HTTP-клайент, вроде там в факторе даже прописан, он как бы за нас… Занас под капотом занимается созданием и, там, условно, удалением, как фредпул, условно, вот этих http-клайентов. Это первая проблема. Вторая проблема, я слышал, связана с ДНС-ами, что Честно, сейчас прям детально не расскажу, потому что давно сталкивался, ну, читал про это, но знаю, что может быть проблема с ДНС-ами, когда у нас закончатся полы подключений, и может случиться такая проблема, что собьется ДНС. Вот.", "output": {"hard_skills": ["bulk update", "EF Core", "HTTP Client Factory", "DNS management"], "soft_skills": ["коммуникабельность", "аналитическое мышление", "умение работать в команде"], "recommendations": ["Углубить знания по самописным решениям, особенно в области оптимизации и работы с EF Core.", "Изучить подробнее проблемы, связанные с DNS и HTTP Client Factory, чтобы уверенно отвечать на вопросы на интервью.", "Практиковаться в объяснении сложных технических концепций более простым языком, чтобы лучше донести свои мысли до собеседников."]}, "chunk_id": 16, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Да, то есть он, скорее, там, не успевает следить за обновлением DNS, если какой-то глобальный Ruby-клиент задан, вот. И когда пул у нас тут к этому толерантнее. То есть у тебя где-то далеко IP-шник поменялся, а он думает, что это ещё старый IP-шник, и, там, ошибки сыпет. Ну да, всё правильно. Окей. А про строки немного поговорим. Вот тут на эти строки они мутабельны. Какие у тебя там, видишь, плюсы и минусы?\nВопрос: Ну, минусы в том, что, условно, допустим, в форриче изменять строку — это прям выстрел в ногу, что, допустим, каждое изменение строки приводит к тому, что у нас создается новая строка. А какие минусы… Ой, ну вот это минусы, да. То есть, по производительности, плюсы. Плюсы строк. Ну, не знаю, можно ли назвать, что, допустим, если у нас есть одна строка с одинаковым названием, то она ссылается на один участок памяти. Насколько это применимо? Ну, вот, не знаю, могу предположить, что это плюс. Плюс строки. Ну, я знаю, что строки — это ссылочный тип данных, но их поведение, оно как у значимого типа данных. То есть, если мы её передаём в метод, то у нас получается копирование строки. Но ты её поменять не можешь. Соответственно, у тебя значение, оно всегда будет постоянное, в итоге. Вот. Я больше, да, имел в виду про то, что её извне, как бы, изменения мы не затронем. Вот. Что ещё про строки? Ну, про стрингбилдер. Слышал, что это классная штука, когда, условно, нужно делать много, там, контентации со строками. Про… Стрингпул слышал тоже. Ну это вот как раз, что у нас, если… Да, интернирование, что если у нас есть, допустим, три строки, и у них одинаковые значения, то они будут ссылаться на единый участок памяти. То есть всегда, имеешь в виду, любые три одинаковые строки? Ну вот, я на практике пробовал с этим поиграться. Допустим, создал перемену x, y. Если у них значение, там, три однёрки, то у них getHashCode, он будет равный. А вот в памяти они на одну область будут ссылаться или нет? А, я разбирался с этим. Ну то есть, у нас при первом создании строки… Хотя, хороший вопрос. Тут, скорее всего, зачем нам и интернирование, стринг-пул? Ну вот да, то есть. Да, да. Ну, как я смотрел, то у нас просто будет ссылание на одну ячейку в памяти. Может быть, это сделано с помощью интернирования строк? Под капотом как-то реализовано хитро.\nОтвет: могу предположить так. Ну, вот эту проблему, скорее, интернирование решает. То есть, она специальная. Если ты будешь интернировать какие-то строки, то да, будет так работать. А знаешь, какие вот по дефолту строки интернируются? Окей, а ты, получается, вот стринг-билдер, да, ты упомянул, вот как, думаю, что будет лучше, если у тебя какой-нибудь метод принимает, там, три короткие строки, там, по три символа, и тебе нужно их, там, сложить, условно, в выдаче, вот что лучше? Конкатенации встроенной, да, их сложить, там, через плюсик или… Через интерполяцию. Или, там, объявить стринг-билдер и через него складывать их и возвращать стримы.\nВопрос: Я смотрел где-то Читал пост касаемо вот этих тоже, ну, всяких прикольных моментов со строками. Я смотрел и помню, что если, допустим, у нас строка маленькая, и нужно сделать какие-то, ну, небольшие преобразования, то конкат в этом случае будет отрабатывать вроде бы быстрее, чем стрингбилдер, потому что стрингбилдер нам нужно, во-первых, инициализировать, под капотом он там выделяет сразу место, достаточно большое. И если у нас строки маленькие, ну то есть нужно с ними небольшие операции сделать, то конкатенация здесь, скорее всего, Будет маст… Ну. выдаст больше производительности.", "output": {"hard_skills": ["Ruby", "DNS", "строки", "стринг-билдер", "стринг-пул", "интернирование строк", "производительность"], "soft_skills": ["аналитическое мышление", "коммуникабельность", "способность к обучению", "критическое мышление"], "recommendations": ["Углубить знания о производительности различных типов данных в Ruby.", "Изучить более детально концепцию интернирования строк и его применение.", "Практиковаться в оптимизации кода с использованием стринг-билдеров и конкатенации.", "Развивать навыки объяснения сложных концепций простым языком для лучшего общения с коллегами."]}, "chunk_id": 17, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Ну да, всё верно. А приходилось тебе вообще какие-нибудь утечки памяти, там, профайлить, анализировать, исправлять?\nВопрос: Какие-нибудь тузами, может, пользовался. Может, ещё бенчмарк.нетом пользовался. Вот, кстати, да-да, бенчмарк.нет я пользовался, но использовал его в рамках F-Core, в рамках коллекций, когда сам по приколу смотрел, там, условно, работу... А, там, Dictionary, и мутабельный… и мутабельного Dictionary. Ну, и мутабельный коллекция, точнее. И Frozen. Вот. Памяти. Со спаном, с пеном немножко поработал, но если вот сейчас разбирать и вспоминать, как он под капотом работает, то я не вспомню вот этого. Ну, Benchmark.net использовал. В контексте строк, да, было? Да, там, да. Я помню, мы сперва… Как сперва у нас вообще был лекция по спанами? Больше с асинхронностью, когда в стейт-машину влезал, ну, под капотом смотрел, во что разворачивается. По памяти не было такого. Окей. А ты вот про «Продикшен», Эрис, заговорил. У вас какая там… Сложность алгоритмическая поиска, например, элементов. А там такая двоякая ситуация, что если у нас, допустим, нет коллизий, то это O1. Если у нас есть коллизия, то у нас получается связанный список, и там… ОАТН, потому что нужно перебрать все элементы, которые есть в рамках линкед-листа, ну, связанного списка.\nОтвет: А Frozen дикшенари вы уже юзали, да?\nВопрос: Нет, нет, ну у нас таких примеров не было прям, не сразу как бы новые фичи юзаем. Я просто их для себя смотрю на практике, сам изучаю, потому что интересно, и вдруг, если пригодится, я сразу знаю.", "output": {"hard_skills": ["профайлинг", "анализ утечек памяти", "использование Benchmark.net", "работа со структурами данных", "алгоритмы", "асинхронное программирование"], "soft_skills": ["самостоятельное изучение", "интерес к новым технологиям", "небольшая изобретательность"], "recommendations": ["Углубите знания в области работы с памятью и оптимизации производительности.", "Попробуйте больше практиковаться с новыми фичами языка, такими как Frozen Dictionary, чтобы быть готовым к их применению в реальных проектах.", "Развивайте навыки решения алгоритмических задач, это поможет вам лучше ориентироваться в сложных ситуациях."]}, "chunk_id": 18, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Да, Frozen — это прикольная тема. То есть он анализирует тип ключа и в зависимости от этого подбирает, там, нужный алгоритм. Да, я видел, там, под капотом прям тоже, ну, дерево, по сути, используется.\nВопрос: Ну, Frozen Dictionary я смотрел. Это прикольная штука, когда, условно, нам нужно загрузить элементы в словарь и больше его никогда не менять. Он в моменте выделяет очень много памяти, а локация происходит, но потом он выигрывает по производительности, как я и смотрел.\nОтвет: У меня ещё вот такой вопрос. Пользовался ли ты System Channel с каналами?\nВопрос: Систем Ченнелс? Ченнел. Я вспоминаю. Ченнел.", "output": {"hard_skills": ["анализ алгоритмов", "работа с Frozen Dictionary", "оптимизация производительности", "понимание системных каналов"], "soft_skills": ["аналитическое мышление", "способность к обучению", "умение вести технический диалог"], "recommendations": ["Углубить знания в области работы с системными каналами.", "Развивать навыки объяснения сложных концепций более простым языком.", "Практиковаться в оптимизации алгоритмов и анализе их производительности."]}, "chunk_id": 19, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Но это вроде бы тема с вип-сокетами связана, правильно? Ну нет, это такие внутренние очереди в дот-нете легковязные. Просто интересный такой в топе. Не, не восьмой, а раньше намного. То есть в шестой они точно были? Может, они в пятом появились? Или в шестом? Что-то такое. Вот, сейчас нашёл, да. Посмотрю, спасибо. Я не слышал про неё.\nВопрос: Раз мы пошли. «I observable»? А, «I observable»! Я помню, мне на собеседовании одном сказали реализовать ивент, который срабатывает при изменении коллекции. И тогда я посмотрел на «Observable Collection», если это про это.\nОтвет: На, я вот когда на Нагуляре писал, там это всё обмазано просто этими штуками. Да, и по дотам тоже. Вот это, знаете, это отдельно либо оно, ну, по производительности немного такое себе не очень, поэтому я не пользовался особо. То есть это подход прям, то есть если ты начинаешь ими пользоваться, то там всё обмазываешь как будто такой.\nВопрос: Какие, знаешь? Расскажи, что такое. Да, примитивы синхронизации делятся на два типа, как я знаю, пользовательские, на уровне ядра операционной системы, и гибридные. Там прикол в том, что вот пользовательские — это, допустим, Mutex. Монитор, что ещё у нас, семафор, они как бы идут напрямую в ядро операционной системы. А гибридные — это Slim-версии. Вот я как вспоминаю, там, семафор Slim, к примеру, что ещё у нас есть из Slim-версии. ReaderWrite, LogSlim вроде бы, что ли. Они как бы крутятся в специальном отдельном спинвейте и нужны для оптимизации, когда очень быстро выполняются у нас Блокировки и вот эти моменты. Вот. На практике использовал Mutex. Обычный лог у нас тоже был. По сути, это монитор. Что ещё? Симафор и Симафор Слим. Вот. Это именно вот в рамках работы. А сам на практике в своих подпроектах писал ещё интерлокт вроде бы на атомарной операции. Пробовал с ним играть. Вот. Как-то так. Новеньких, вот. Там я копался прям. Ну, сказать было интересно. Не сказать, но прикольно, что вот его посмотрел. Угу. Так.", "output": {"hard_skills": ["VIP-сокеты", "Observable Collection", "примитивы синхронизации", "Mutex", "Monitor", "Semaphore", "Slim-версии", "ReaderWriter", "LogSlim", "атомарные операции"], "soft_skills": ["умение анализировать", "интерес к новым технологиям", "внимательность к деталям", "способность к самообучению"], "recommendations": ["Углубить знания в области производительности и оптимизации потоков.", "Практиковаться в реализации паттернов проектирования, связанных с асинхронностью.", "Уточнить и систематизировать знания о различных примитивах синхронизации и их применении.", "Попробовать реализовать больше примеров с использованием Observable Collection для лучшего понимания."]}, "chunk_id": 20, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: САД, вот эти вот всё. Да, с докера начнём.\nВопрос: Сред. Сперва у нас всё в ИСе вообще разворачивалось, но потом пришли к использованию докер, создавал докер-контейнеры, по сути, с докер-файлом работал. Не сказать, что прям все детальные команды условно знаю, в процессе разбираюсь. Ну и плюс, когда свои, там, пэт-проекты пишу, Так или иначе, тоже использую докер. Очень удобно разворачивать всё.\nОтвет: Угу, а вот мультистейдж билды, например, знаешь, что такое? Мультистейдж билды? А как вот, как докер-файл был устроен, словно, вот, для дотнет-проекта?\nВопрос: А, ну, просто, по сути, стандартные команды, там, run, в зависимости от того, нужно ли использовать копирование некоторых, допустим, файлов, там, upsetting.json, нужно ли было копировать, делать mount, как я знаю, из операции. Базовый образ изначально какой был?", "output": {"hard_skills": ["Docker", "Dockerfile", "мультистейдж билды", "развертывание приложений"], "soft_skills": ["умение учиться", "проектное мышление", "коммуникация"], "recommendations": ["Углубить знания в мультистейдж билдах Docker для улучшения оптимизации образов.", "Изучить больше команд Docker и их применение для повышения уверенности в работе с ним.", "Практиковать написание более сложных Dockerfile для различных типов проектов, чтобы расширить свои навыки."]}, "chunk_id": 21, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Базовый образ. Вот, дотнайте из SDK и рантайма, например.\nВопрос: Базовый образ, ну вроде… Блин, читаю туплю, ну вроде бы рантайм, что ли, шёл. Там, на самом деле, сбилдить можно в СДК только, получается, проект. А запускать и там, и там, например, можно. Ну, я запускал только через, именно вот, Докер, через там, PowerShell запускаю, команду выполняю, и всё. Поэтому здесь могу тупить немного.\nОтвет: но в докер файле как раз таки есть мультистейдж то есть ты сначала from sdk делаешь базовый образ sdk гильдишь в нем проект но он много весит то есть а если ты в нем и запускать будет что у тебя докер образ будет в итоге огромный там большой вот поэтому Второй стейдж используют, то есть берут from-рунтайм, и вот эти артефакты из SDK перекидывают в легковесный рунтаймовый образ, и уже там запускают прилагу, чтобы она мало весила, без там лишнего всякого. А про кэширование слоев в докере знаешь что-нибудь? Как вот оптимизировать можно? Ну вот мы сейчас поговорили, как, например, можно оптимизировать, там, размер, да, более раковестный, там, использовать базовые образы, например, вот как скорость сборки.\nВопрос: Скорой сборки, кэширование. То есть у тебя не было особо таких кейсов, чисто локального, да, юзов? Ну окей. Ну нет, ну просто как там, по работе нужно… У нас была документация, условно, в зависимости её выполняешь команды, если что-то не получается, уже разбираешься. Вот прям мультистейдж и кэширование не сталкивался.", "output": {"hard_skills": ["Docker", "SDK", "Runtime", "Multi-stage builds", "Layer caching"], "soft_skills": ["Communication", "Problem-solving", "Adaptability"], "recommendations": ["Углубите знания о мультистадийных сборках и оптимизации образов в Docker.", "Практикуйте кэширование слоев в Docker для ускорения сборки.", "Изучите примеры реальных кейсов использования Docker в проектах.", "Работайте над улучшением четкости изложения своих мыслей во время обсуждений."]}, "chunk_id": 22, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: В OPCI-CD, получается, у вас это все настроено строена на было кем-то то есть до 2 в санте условно туда\nВопрос: Не лазил, не приходилось там что менять. Ну, сам настройку не выполнял, потому что всё работало из-под коробки. Условно, залил свою пачку изменений, нажал старт и вливается там на прот или стейдж, условно. Там пайплайны выполняются. Можно к ним прикрутить разные правила. Там, допустим, в зависимости от названия ветки мы ставим разрешение, там, мердж или нет. А с Github'ом… У нас Github тоже использовался, но Не смотрел пайплайны, вот как они там выполняются, только в рамках гитхаба немного посмотрел.\nОтвет: Аркестратор у вас какой был? То есть вы куда деплоились?\nВопрос: Аркистрактор. Да, там у нас он использовался на… Ну, тоже в рамках локальной какие-то. Создать сессии быстренько для тестирования, вот. Ну, у нас всё есть в подкоробке, я прям в кибернетизм вообще не лазил. Это тоже, я как слышал, тяжёлая… Вот вам, получается, вот этот файлик диплоя-то тоже кто-то описывал?", "output": {"hard_skills": ["OPCI-CD", "GitHub", "пайплайны", "деплой", "тестирование"], "soft_skills": ["командная работа", "проектное мышление", "способность к обучению"], "recommendations": ["Углубить знания в области Kubernetes для повышения квалификации.", "Изучить принципы работы с пайплайнами и CI/CD для более глубокой технической экспертизы.", "Постараться принимать более активное участие в настройках и управлении процессами, чтобы развивать практические навыки."]}, "chunk_id": 23, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: дебопс какой-нибудь или как? Вот именно файл релиза в Кубер.\nВопрос: У нас такового прям отдельной роли для DevOps-а не было. У нас был архитектор, он, по сути, был и мамой, и папой, ну, там, закрывал вот эти бизнес-задачи. Угу. То есть, условно,\nОтвет: Не приходилось, да, менять какую-то конфигурацию, диплой, вот это вот всё? Нет, я прям… А вот со стороны кода, вот со стороны приложения, ну, были бы какие-то требования, вот какие-нибудь health-чеки, например, написать, там, какие-то обязательные пробы, вот, для кубернетиса?\nВопрос: А, конкретно для кубернетиса я не писал тоже такого. Хеллчеки я писал и работал даже с библиотекой, там, Hankfire для UI-ки, просмотр. Джоб — это вообще для Джоб вроде связано, да, Hankfire с Джобом связано. Ну, хеллчеки я писал.", "output": {"hard_skills": ["Кубернетис", "Hankfire", "разработка health-чеки"], "soft_skills": ["умение работать в команде", "адаптивность", "внимание к деталям"], "recommendations": ["Углубить знания в области DevOps и CI/CD процессов.", "Работать над проектами, связанными с конфигурацией и деплоем приложений.", "Развивать навыки решения бизнес-задач в команде."]}, "chunk_id": 24, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: Для Аки.\nВопрос: У нас был health check самый простой для бдшки. Просто, условно, делаем select, если база выполняется, значит, она жива. Потом health check у нас был для одного из микросервисов важных, который отвечал за, вот, как раз, проект C2C, то есть это просмотр Работы нашей биржи. Там прям полностью, ну, там UI-ки не было красивые, там просто огромный текст был, и по нему мы смотрели в самых начальных приложениях, типа, работает или нет.\nОтвет: Вот. Что ещё? Вот эти хеллчеки, они на что влияли?\nВопрос: По итогу, вот. Ну, с помощью хелс-чека можно было посмотреть, там, активен или… Ну, работает ли в данный момент наш, условно, наше ПО на сервере, крутится ли оно там. У нас просто за этим, типа, следили саппорты, можно их так назвать, типа. И они звонили. А так, я могу предположить, тут, скорее всего, вопрос идёт к метрикам — Графан или Приметеус. Да, во, то есть, у нас Графана была, с ней я поработал. Но в основном нам просто звонили, то есть, если что-то ночью падает, звонили, вот так. Ну это алерты как раз, я не знаю, можно ли это назвать. Уведомления у нас приходили тоже. А вот вспомнил, когда что-то ломалось, приходили просто в слаке от бота. Но ночью, к примеру, фиг посмотришь, звонки просто тупо шли. Ну да, понятно. Ну, собственно. А метрики, вот, какие-то вы отслеживали, вот, в приложении? Counter, я помню, точно использовался у нас. Метрики. Ну, у нас очень большая была метрика по нашим ивентам аналитическим, там, с какой скоростью, условно, выполняются запросы. Вот больше для этого", "output": {"hard_skills": ["знание баз данных", "опыт работы с микросервисами", "знание Grafana", "знание Prometheus", "аналитика метрик"], "soft_skills": ["умение работать в команде", "коммуникабельность", "умение решать проблемы", "гибкость"], "recommendations": ["Углубить знания в области мониторинга и алертинга для повышения эффективности работы.", "Изучить лучшие практики визуализации данных в Grafana.", "Развивать навыки работы с метриками и аналитикой для более глубокого понимания производительности приложений."]}, "chunk_id": 25, "source_file": "dialoge_interview_2_final.json"}
{"instruction": "Представь, что ты виртуальный наставник. Определи сильные и слабые стороны кандидата по диалогу и сформулируй рекомендации.", "input": "Ответ: А что ещё метрики? Какие мы смотрели? Вот эти метрики, они как были реализованы? То есть это какая-то сторонняя либо там была\nВопрос: Они выставлялись в каком-то формате, там, OpenTelemetry, может, слышал про это. Вот OpenTelemetry как раз у нас и использовался. Я его и на практике тоже с ним повозился сам. Он же обычно идёт OpenTelemetry и плюс там, графана. Вот, условно, OpenTelemetric, он, не знаю, с Prometheus, он вроде тоже связан должен быть. Вот, это связка была.\nОтвет: Угу. А вот логи, ошибки — как это отслеживали? А, да, у нас.\nВопрос: У нас была своя собственная кастомная ПО для логов. В основном мы сперва, ну, мы сразу начали использовать неориентированную базу данных Clickhouse, потому что она как раз для сбора данных очень классная штука. Там под капотом движки, и в зависимости от движков, ну, там, в общем, движки на любой вкус, и как раз для логов они идеально подходили. и просто в нашей собственной системе Они там и показывались. Можно было статус выбрать, по определённым лейблам найти информацию, там, по session id, по дате и так далее. Они пошли чуть дальше, чем Елка. Да, а вы какой-нибудь Centric не использовали? Нет, чего-то такое вообще не видел, что у нас она использовалась. Ну, может, использовалась, может, я просто до неё не доходил. У нас проект был огромный, и бывало такое, что не всегда прям со всеми инструментами, ну, можно было поработать. А, да, у нас… Да, да. Я использовал интеграционный тест для микросервисов, а юнит-тесты на.NET и функциональные на Python. Правда, с функциональными было немножко. Вот. У нас на проекте вообще тестов, от слова, было совсем ноль, их просто не было. Вот. А, собственно, когда мы выкатывали новые какие-то фичи, то не всегда было такое, что, условно, тестировщик всё проверит, и мы сами могли всё проверить, что всё работает идеально. Поэтому очень часто встречались серьёзные ошибки на продакшене, что Ну, приводили, так сказать, к серьезным проблемам. И я, собственно, предложил идею. У нас команда на этом проекте была из пяти человек, чтобы начать писать юнит-тесты. Вот. Я занялся написанием... юнитесты для новых фич, а ребята как раз параллельно для старых, условно важных, функциональных моментов писали для них юнитесты. А знаешь, разница между юнит-тестами и компонентными тестами? — Компонентными? — Ну да. Ну, просто, возможно, ты писал не совсем юнит-тест, а компонентный тест, потому что они… А интеграционные в целом большой скоб каких-то компонентов под себя подразумевают и тестируют. Но в основном в рамках «Монолита» у нас был чисто МОК одного сервиса. С интеграционными мы уже делали использование разных, там, базы данных, там. А вот как… Ну, это, можно сказать, и был компонентный. Я думал, что это синоним, условно. Да, просто интеграционный тест — это ещё, как бы, отдельный этап. Угу, нет, у нас уже была развернута бд-шка, у нас тоже использовался, по сути, кликхаус для… Ну, туда попадали логи, все наши разные фичи, которые мы тестировали, связанные с какими-то… Большим объём данных, вот. У нас в основном использовался клик для этих ситуаций, чтобы по… Ну, из клихауса, как вот я на практике встречал, можно с помощью, как сказать, кавычек, доставать определённые данные там. Ну, семейство данных. Вот. У нас она уже была развернута, мы просто обращались к ней и получали набор данных. И всё, в целом. Как-то… А на ПГ у вас не было тестов? На ПГ? Да, у нас вот интеграционные часто были именно с Тлихаусом. На ПГ у нас были тесты, но он тоже был развернут в рамках уже отдельного сервера. Мы локально не поднимали их. Понятно. Ага. А, нет, нам нужно было на функциональных на Пайтоне тестировать какие-то… Я уже не помню, что-то честное я тестировал, это было давно, но вроде бы обращение к очереди, там, с эксченджами. Мы Рэббит и работоспособность Кавки смотрели с помощью Пайтон-тестов. В этом и проблема, что нужно было всем ребятам, как бы, поддерживать это всё потом. Вспоминаю, у нас использовалась такая либо как автофикстура, что ли. Автофикстура, да. Да, она как бы сразу нам и приводила нужный объём данных.", "output": {"hard_skills": ["OpenTelemetry", "Grafana", "Prometheus", "ClickHouse", ".NET", "Python", "интеграционное тестирование", "юнит-тестирование", "функциональное тестирование"], "soft_skills": ["командная работа", "инициативность", "решение проблем", "планирование", "обсуждение технических аспектов"], "recommendations": ["Углубитесь в изучение различий между юнит-тестами, компонентными тестами и интеграционными тестами для более точного применения в проектах.", "Рассмотрите возможность использования более современных инструментов для работы с логами и метриками, чтобы улучшить процесс мониторинга.", "Уделите внимание улучшению качества тестирования, чтобы сократить количество ошибок на продакшене.", "Продолжайте развивать навыки работы с базами данных и их интеграцией в процессы тестирования.", "Работайте над эффективной коммуникацией в команде, чтобы избежать недопонимания в технических аспектах."]}, "chunk_id": 26, "source_file": "dialoge_interview_2_final.json"}
